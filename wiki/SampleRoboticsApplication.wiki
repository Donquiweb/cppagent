#labels Featured
#design doc for sample robotics software

= Introduction =

Imagine a simple robot with one camera sensor and two tank-drive wheels.  This document describes an example architecture using agent-based programming.


= Vision =

We will call the first agent FrameGrabber and put him in charge of reading frames from the camera.  FrameGrabber needs to do a little processing in order to combine the RGB color planes into a jpeg.  The resulting compressed images are sent to two other agents, LineDetector and ObjectDetector.

LineDetector reads a frame and uses a line detection algorithm to find white lines on the ground.  The lines are encoded in slope-intercept form and sent to the Model agent.

ObjectDetector filters for orange to detect cones in each frame.  These objects are encoded as points and sent to the Model agent.


= Planning =

Model keeps track of objects and boundary lines and stores them in a data structure called the environment model.  Model also reads paths and sends them to the Driver agent if the paths do not intercept an obstacle or line.

The PathGenerator agent reads target waypoints and generates possible ways to get there.  PathGenerator first tries a straight-line path, and then branches out to many variants.  Each potential path is sent to Model for evaluation.

The Navigator agent reads waypoints from a file and sends them to PathGenerator.


= Control =

The Driver agent reads the latest unobstructed path and directs the LeftWheel and RightWheel agents to follow the path.

LeftWheel and RightWheel read target speeds and send control signals to the actuators.